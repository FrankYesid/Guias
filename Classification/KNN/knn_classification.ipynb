{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Classification on MNIST Dataset (Small Sample)\n",
        "\n",
        "This notebook demonstrates how to apply K-Nearest Neighbors (KNN) classification using a small subset of the MNIST dataset. We will follow the typical machine learning pipeline, including data loading, preprocessing, model training, and evaluation.\n"
      ],
      "metadata": {
        "id": "DvLbFJ1762Tv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92w8sXen5std"
      },
      "outputs": [],
      "source": [
        "# 1. Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import utils  # Custom utility functions\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load the MNIST Dataset\n",
        "\n",
        "We load the training and test data using the utility functions from `utils.py`. The training data consists of a small subset of the MNIST dataset, while the test data is the full MNIST test set.\n"
      ],
      "metadata": {
        "id": "PiwWm4te6-z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the dataset CSV files\n",
        "train_path = 'data/mnist_train_small.csv'\n",
        "test_path = 'data/mnist_test.csv'\n",
        "\n",
        "# Load data\n",
        "X_train, y_train, X_test = utils.load_data(train_path, test_path)\n",
        "\n",
        "# Check the shape of the datasets\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")\n"
      ],
      "metadata": {
        "id": "OJ8kDj-666qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Preprocessing\n",
        "\n",
        "Next, we normalize the pixel values to a range of [0, 1] to ensure consistent scaling. This is crucial for the KNN algorithm to perform optimally.\n"
      ],
      "metadata": {
        "id": "kyWUyxQQ7A5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "X_train = utils.normalize_data(X_train)\n",
        "X_test = utils.normalize_data(X_test)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set shape: {X_train_split.shape}, Validation set shape: {X_val.shape}\")\n"
      ],
      "metadata": {
        "id": "pLzfBJNX7BLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Visualize Sample Data\n",
        "\n",
        "Before training, let's visualize some sample images from the dataset.\n"
      ],
      "metadata": {
        "id": "hGfkAKuB7EAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a few sample images from the training set\n",
        "sample_indices = [0, 1, 2, 3, 4]\n",
        "utils.plot_multiple_samples(X_train_split, y_train_split, sample_indices)\n"
      ],
      "metadata": {
        "id": "2MLxwOa17F0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Train the K-Nearest Neighbors Model\n",
        "\n",
        "We train the KNN model with `k=3` and evaluate its performance on the validation set. The optimal value of `k` can be fine-tuned later.\n"
      ],
      "metadata": {
        "id": "J6HTUEH37ifD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the KNN model with k=3\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Train the model\n",
        "knn.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = knn.predict(X_val)\n",
        "\n",
        "# Evaluate accuracy\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "gAHhzvIo7i0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Evaluate the Model\n",
        "\n",
        "We generate and display a confusion matrix and classification report to better understand the model's performance.\n"
      ],
      "metadata": {
        "id": "FaIVB7CQ8GV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
        "class_report = classification_report(y_val, y_val_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n",
        "\n",
        "# Plot and save the confusion matrix\n",
        "os.makedirs('results', exist_ok=True)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.savefig('results/confusion_matrix.png')\n",
        "plt.show()\n",
        "\n",
        "# Save the classification report to a file\n",
        "with open('results/classification_report.txt', 'w') as f:\n",
        "    f.write(class_report)\n"
      ],
      "metadata": {
        "id": "kq7C50jA8G2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Predict on the Test Set\n",
        "\n",
        "Finally, we use the trained KNN model to make predictions on the test set and save the predictions to a CSV file for further evaluation.\n"
      ],
      "metadata": {
        "id": "YBJKhxTN8K4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_test_pred = knn.predict(X_test)\n",
        "\n",
        "# Save the test set predictions\n",
        "pd.DataFrame(y_test_pred, columns=['Label']).to_csv('results/test_predictions.csv', index_label='ImageId')\n"
      ],
      "metadata": {
        "id": "hlaHSWer8LH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Save the Validation Accuracy\n",
        "\n",
        "We also save the validation accuracy to a text file in the `results` folder.\n"
      ],
      "metadata": {
        "id": "3PNbYkBV8UfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the validation accuracy\n",
        "with open('results/validation_accuracy.txt', 'w') as f:\n",
        "    f.write(f\"Validation Accuracy: {val_accuracy:.4f}\\n\")\n"
      ],
      "metadata": {
        "id": "6ApNCC-Z8U5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Conclusion\n",
        "\n",
        "This notebook demonstrated how to implement and evaluate a K-Nearest Neighbors classifier on a small subset of the MNIST dataset. The results, including the confusion matrix, classification report, and test predictions, have been saved to the `results` folder for further analysis.\n"
      ],
      "metadata": {
        "id": "RjODGycW8iHc"
      }
    }
  ]
}
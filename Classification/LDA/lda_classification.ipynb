{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azLrvN18wU1F"
      },
      "source": [
        "# LDA Classification on MNIST Dataset\n",
        "\n",
        "This notebook demonstrates how to apply Linear Discriminant Analysis (LDA) for digit classification using the MNIST dataset. The notebook is organized into sections covering data loading, preprocessing, model training, and evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Import Libraries\n",
        "\n",
        "We start by importing the necessary libraries, including the utility functions from `utils.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1_MRm7OBwU1H",
        "outputId": "9f1519df-1785-43e0-9b8e-df41efcf9a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-32d1425b25ec>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import utils\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrFV-yE8wU1J"
      },
      "source": [
        "## 2. Load the MNIST Dataset\n",
        "\n",
        "Next, we load the MNIST dataset using the `load_data` function from `utils.py`. The dataset is split into features (`X_train`, `X_test`) and labels (`y_train`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bndo1_wwU1J"
      },
      "outputs": [],
      "source": [
        "# Paths to the dataset CSV files\n",
        "train_path = 'data/mnist_train_small.csv'\n",
        "test_path = 'data/mnist_test.csv'\n",
        "\n",
        "# Load data\n",
        "X_train, y_train, X_test = utils.load_data(train_path, test_path)\n",
        "\n",
        "# Check the shape of the datasets\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWtMH7OAwU1K"
      },
      "source": [
        "## 3. Data Preprocessing\n",
        "\n",
        "We normalize the pixel values to [0, 1] and split the training data into a training and validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90bDzHs1wU1K"
      },
      "outputs": [],
      "source": [
        "# Normalize the data\n",
        "X_train = utils.normalize_data(X_train)\n",
        "X_test = utils.normalize_data(X_test)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set shape: {X_train_split.shape}, Validation set shape: {X_val.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWlmq56BwU1L"
      },
      "source": [
        "## 4. Visualize Sample Data\n",
        "\n",
        "Before training, let's visualize some sample images and their corresponding labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD2t1DMmwU1L"
      },
      "outputs": [],
      "source": [
        "# Plot a few sample images from the training set\n",
        "sample_indices = [0, 1, 2, 3, 4]\n",
        "utils.plot_multiple_samples(X_train_split, y_train_split, sample_indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDv8bzPGwU1L"
      },
      "source": [
        "## 5. Apply Linear Discriminant Analysis (LDA)\n",
        "\n",
        "We now train an LDA model on the training data and evaluate its performance on the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eVEqzDhwU1L"
      },
      "outputs": [],
      "source": [
        "# Initialize and train the LDA model\n",
        "lda = LDA()\n",
        "lda.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = lda.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
        "class_report = classification_report(y_val, y_val_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaQaCRBAwU1M"
      },
      "source": [
        "## 6. Save Results\n",
        "\n",
        "Now, let's save the confusion matrix, classification report, and other results to the `results` directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSCnXx5fwU1M"
      },
      "outputs": [],
      "source": [
        "# Apply LDA to reduce dimensions to 2\n",
        "lda_2d = LDA(n_components=2)\n",
        "X_train_2d = lda_2d.fit_transform(X_train_split, y_train_split)\n",
        "\n",
        "# Plot the 2D decision boundaries (this is more illustrative than practical)\n",
        "utils.plot_sample(X_train_2d, y_train_split, index=0)  # Plotting the first sample after reduction\n",
        "\n",
        "\n",
        "# Create results directory if it doesn't exist\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "# Save the validation accuracy\n",
        "with open('results/validation_accuracy.txt', 'w') as f:\n",
        "    f.write(f\"Validation Accuracy: {val_accuracy:.4f}\\n\")\n",
        "\n",
        "# Save the classification report\n",
        "with open('results/classification_report.txt', 'w') as f:\n",
        "    f.write(class_report)\n",
        "\n",
        "# Plot and save the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.savefig('results/confusion_matrix.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-UU1lGiwU1M"
      },
      "source": [
        "## 7. Predict on the Test Set\n",
        "\n",
        "Finally, we use the trained LDA model to make predictions on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC1dU9FmwU1M"
      },
      "outputs": [],
      "source": [
        "# Apply LDA to reduce dimensions to 2\n",
        "lda_2d = LDA(n_components=2)\n",
        "X_train_2d = lda_2d.fit_transform(X_train_split, y_train_split)\n",
        "\n",
        "# Plot the 2D decision boundaries\n",
        "plt.figure(figsize=(10, 8))\n",
        "scatter = plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train_split, cmap='tab10', alpha=0.6)\n",
        "plt.title('LDA 2D Projection of MNIST Data')\n",
        "plt.xlabel('LD1')\n",
        "plt.ylabel('LD2')\n",
        "plt.colorbar(scatter, label='Digit')\n",
        "plt.savefig('results/lda_2d_projection.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-jdNes9wU1N"
      },
      "source": [
        "## 8. Predict on the Test Set and Save Predictions\n",
        "\n",
        "Finally, we use the trained LDA model to make predictions on the test set and save the predictions to a CSV file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIQTZUItwU1N"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_test_pred = lda.predict(X_test)\n",
        "\n",
        "# Save the test set predictions\n",
        "pd.DataFrame(y_test_pred, columns=['Label']).to_csv('results/test_predictions.csv', index_label='ImageId')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy3MU7_uwU1N"
      },
      "source": [
        "## 9. Conclusion\n",
        "\n",
        "This notebook demonstrated how to use Linear Discriminant Analysis (LDA) for digit classification using the MNIST dataset. The results, including the confusion matrix, classification report, 2D projection, and test predictions, have been saved to the `results` folder for further analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o62c2QuZwU1N"
      },
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
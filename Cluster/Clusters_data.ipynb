{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Methods on MNIST Dataset\n",
    "\n",
    "This notebook demonstrates the use of various clustering methods on the MNIST dataset. We will compare the performance of different clustering techniques using evaluation metrics such as Silhouette Score and Dunn Index. The dataset is located in the `./data` folder.\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "- Brief introduction to clustering and its applications.\n",
    "- Overview of the clustering methods we'll apply:\n",
    "  - K-means Clustering\n",
    "  - Agglomerative Hierarchical Clustering\n",
    "  - DBSCAN\n",
    "- Evaluation Metrics:\n",
    "  - Inertia (for K-means)\n",
    "  - Silhouette Score\n",
    "  - Dunn Index\n",
    "\n",
    "## 2. Load MNIST Dataset\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import utils  # Assuming utils.py contains functions to load data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load training and test data\n",
    "train_path = './data/mnist_train.csv'\n",
    "test_path = './data/mnist_test.csv'\n",
    "\n",
    "X_train, y_train = utils.load_data(train_path, test_path)\n",
    "\n",
    "# Preprocess data (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Display shape of the dataset\n",
    "print(f\"Training data shape: {X_train_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clustering Methods\n",
    "### 3.1. K-means Clustering\n",
    "K-means is a partitioning method that divides the dataset into K clusters by minimizing the in-cluster variance (inertia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Initialize KMeans with 10 clusters (for 10 digits)\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "kmeans.fit(X_train_scaled)\n",
    "\n",
    "# Predict the clusters\n",
    "kmeans_labels = kmeans.predict(X_train_scaled)\n",
    "\n",
    "# Evaluation metrics\n",
    "inertia = kmeans.inertia_  # Measure of how tightly clusters are packed\n",
    "silhouette_avg = silhouette_score(X_train_scaled, kmeans_labels)\n",
    "\n",
    "print(f'K-means Inertia: {inertia}')\n",
    "print(f'K-means Silhouette Score: {silhouette_avg}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Agglomerative Hierarchical Clustering\n",
    "This method builds a hierarchy of clusters by either merging or splitting them based on distance measures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "# Fit the agglomerative clustering model\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=10)\n",
    "agg_labels = agg_clustering.fit_predict(X_train_scaled)\n",
    "\n",
    "# Evaluation metrics\n",
    "silhouette_avg = silhouette_score(X_train_scaled, agg_labels)\n",
    "\n",
    "print(f'Hierarchical Clustering Silhouette Score: {silhouette_avg}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. Dendrogram: \n",
    "visualize the hierarchy of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dendrogram to visualize the hierarchy of clusters\n",
    "dendrogram = sch.dendrogram(sch.linkage(X_train_scaled[:500], method='ward'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. DBSCAN (Density-Based Clustering)\n",
    "DBSCAN is a density-based clustering method that groups points that are closely packed together while marking points that are far from others as noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Fit DBSCAN\n",
    "dbscan = DBSCAN(eps=3, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(X_train_scaled)\n",
    "\n",
    "# Evaluation metrics\n",
    "silhouette_avg = silhouette_score(X_train_scaled, dbscan_labels)\n",
    "\n",
    "print(f'DBSCAN Silhouette Score: {silhouette_avg}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation of Clustering Methods\n",
    "### 4.1. Silhouette Score\n",
    "The silhouette score measures how similar an object is to its own cluster compared to other clusters. Values range from -1 to 1, where higher is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate silhouette scores for each method\n",
    "kmeans_silhouette = silhouette_score(X_train_scaled, kmeans_labels)\n",
    "agg_silhouette = silhouette_score(X_train_scaled, agg_labels)\n",
    "dbscan_silhouette = silhouette_score(X_train_scaled, dbscan_labels)\n",
    "\n",
    "print(f'K-means Silhouette Score: {kmeans_silhouette}')\n",
    "print(f'Hierarchical Clustering Silhouette Score: {agg_silhouette}')\n",
    "print(f'DBSCAN Silhouette Score: {dbscan_silhouette}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Dunn Index (optional)\n",
    "Dunn Index is another clustering evaluation metric that aims to identify clusters that are compact and well-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Dunn Index (use external library or custom function)\n",
    "from dunn_index import dunn\n",
    "\n",
    "kmeans_dunn = dunn(X_train_scaled, kmeans_labels)\n",
    "agg_dunn = dunn(X_train_scaled, agg_labels)\n",
    "dbscan_dunn = dunn(X_train_scaled, dbscan_labels)\n",
    "\n",
    "print(f'K-means Dunn Index: {kmeans_dunn}')\n",
    "print(f'Hierarchical Clustering Dunn Index: {agg_dunn}')\n",
    "print(f'DBSCAN Dunn Index: {dbscan_dunn}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Results to Results Folder\n",
    "Save clustering results, metrics, and visualizations to the results/ folder.\n",
    "### 5.1. Save Silhouette Score and Dunn Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save silhouette scores\n",
    "with open('./results/silhouette_scores.txt', 'w') as f:\n",
    "    f.write(f'K-means Silhouette Score: {kmeans_silhouette}\\n')\n",
    "    f.write(f'Hierarchical Clustering Silhouette Score: {agg_silhouette}\\n')\n",
    "    f.write(f'DBSCAN Silhouette Score: {dbscan_silhouette}\\n')\n",
    "\n",
    "# Save Dunn Index (optional)\n",
    "with open('./results/dunn_index.txt', 'w') as f:\n",
    "    f.write(f'K-means Dunn Index: {kmeans_dunn}\\n')\n",
    "    f.write(f'Hierarchical Clustering Dunn Index: {agg_dunn}\\n')\n",
    "    f.write(f'DBSCAN Dunn Index: {dbscan_dunn}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Save Clustering Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize clusters (e.g., PCA 2D projection)\n",
    "def plot_clusters(X, labels, title, filename):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', s=50)\n",
    "    plt.title(title)\n",
    "    plt.savefig(f'./results/{filename}')\n",
    "    plt.show()\n",
    "\n",
    "# Plot K-means clusters using PCA projection\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train_scaled)\n",
    "plot_clusters(X_pca, kmeans_labels, 'K-means Clustering', 'kmeans_clusters.png')\n",
    "\n",
    "# Similar plots for other methods...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "- Compare the clustering methods based on the evaluation metrics and visualizations.\n",
    "- Summarize the strengths and weaknesses of each method.\\\n",
    "- Choose the best method for the MNIST dataset based on metrics like the Silhouette Score and Dunn Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "This notebook covers a range of clustering methods, uses metrics to compare them, and saves the results in a structured manner. It includes methods like K-means, Agglomerative Clustering, and DBSCAN, along with their evaluation and visualization steps. The MNIST dataset is used as an example to demonstrate each methodâ€™s performance.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

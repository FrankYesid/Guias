# Demostración de LLMs y RAG (Retrieval-Augmented Generation)

Este repositorio contiene un cuaderno interactivo que explica paso a paso cómo funcionan los Modelos de Lenguaje Grande (LLMs) y cómo integrar la estructura RAG (Retrieval-Augmented Generation) para realizar consultas basadas en datos externos.

## Contenido

### 1. Introducción a LLMs
- Breve explicación sobre qué son los Modelos de Lenguaje Grande.
- Principios básicos de su entrenamiento y funcionamiento.

### 2. ¿Qué es RAG?
- Definición de Retrieval-Augmented Generation.
- Cómo mejora las respuestas al enriquecerlas con datos específicos.

### 3. Implementación paso a paso
- Ejemplo práctico para comprender el flujo entre el LLM y el sistema de recuperación.
- Simulación de una consulta en un sistema de RAG.

### 4. Conclusión
- Beneficios de los sistemas RAG para aplicaciones reales.
- Limitaciones actuales de los LLMs y cómo mitigarlas.

---

## Requisitos

### Software
- Python 3.8 o superior.
- Jupyter Notebook o JupyterLab para ejecutar el cuaderno.

### Librerías de Python
Se utilizan las siguientes librerías. Puedes instalarlas con:
```bash
pip install openai langchain pandas faiss-cpu

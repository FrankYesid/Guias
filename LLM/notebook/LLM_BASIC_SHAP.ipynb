{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo Funciona\n",
    "Modelo LLM:\n",
    "\n",
    "Utilizamos un modelo de Hugging Face (distilbert-base-uncased) configurado para tareas de clasificación de texto.\n",
    "Este modelo devuelve un puntaje de similitud entre el texto procesado (consulta + texto objetivo).\n",
    "División en Palabras:\n",
    "\n",
    "La consulta se divide en palabras para que SHAP pueda evaluar la importancia de cada una.\n",
    "predict_text:\n",
    "\n",
    "Genera texto filtrado basado en las palabras activas y calcula un puntaje de similitud con el modelo LLM.\n",
    "Referencia SHAP:\n",
    "\n",
    "Una matriz aleatoria de referencia ayuda a SHAP a generar explicaciones al comparar diferentes combinaciones de palabras.\n",
    "Visualización:\n",
    "\n",
    "Se utiliza shap.force_plot para mostrar cómo cada palabra contribuye al puntaje de similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Modelo de embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Consulta del usuario\n",
    "query = \"¿Cómo ayuda la cúrcuma a la salud?\"\n",
    "\n",
    "# Dividir la consulta en palabras\n",
    "words = query.split()\n",
    "\n",
    "# Función para generar embeddings de cada palabra\n",
    "def word_to_vector(word):\n",
    "    return model.encode([word])[0]\n",
    "\n",
    "# Generar el vector completo para la consulta\n",
    "query_vector = model.encode([query])[0]\n",
    "\n",
    "# Definir una función de predicción que combine palabras\n",
    "def predict_text(words_to_keep):\n",
    "    \"\"\"Genera el vector para la consulta solo con palabras seleccionadas.\"\"\"\n",
    "    # Convertir el array booleano en una frase filtrada\n",
    "    filtered_query = \" \".join([words[i] for i in range(len(words)) if words_to_keep[i] > 0.5])\n",
    "    \n",
    "    # Si no hay palabras seleccionadas, retorna un vector nulo\n",
    "    if not filtered_query.strip():\n",
    "        return np.zeros_like(query_vector)\n",
    "    \n",
    "    # Retornar el embedding del texto filtrado\n",
    "    return model.encode([filtered_query])[0]\n",
    "\n",
    "# Crear una referencia (matriz) para SHAP (conjunto de palabras completo)\n",
    "reference = np.eye(len(words))  # Cada fila representa una palabra activa\n",
    "\n",
    "# Crear el explicador SHAP\n",
    "explainer = shap.KernelExplainer(predict_text, reference)\n",
    "\n",
    "# Calcular los valores SHAP para la consulta completa\n",
    "shap_values = explainer.shap_values(np.ones(len(words)))\n",
    "\n",
    "# Visualizar los valores SHAP\n",
    "shap.force_plot(explainer.expected_value, shap_values, words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

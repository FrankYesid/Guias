{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo Funciona\n",
    "Modelo LLM:\n",
    "\n",
    "Utilizamos un modelo de Hugging Face (distilbert-base-uncased) configurado para tareas de clasificación de texto.\n",
    "Este modelo devuelve un puntaje de similitud entre el texto procesado (consulta + texto objetivo).\n",
    "División en Palabras:\n",
    "\n",
    "La consulta se divide en palabras para que SHAP pueda evaluar la importancia de cada una.\n",
    "predict_text:\n",
    "\n",
    "Genera texto filtrado basado en las palabras activas y calcula un puntaje de similitud con el modelo LLM.\n",
    "Referencia SHAP:\n",
    "\n",
    "Una matriz aleatoria de referencia ayuda a SHAP a generar explicaciones al comparar diferentes combinaciones de palabras.\n",
    "Visualización:\n",
    "\n",
    "Se utiliza shap.force_plot para mostrar cómo cada palabra contribuye al puntaje de similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modelo de lenguaje de Hugging Face\n",
    "llm = pipeline(\"text-classification\", model=\"distilbert-base-uncased\", return_all_scores=True)\n",
    "\n",
    "# Consulta y texto objetivo\n",
    "query = \"How does turmeric help in health?\"\n",
    "target_text = \"Turmeric is beneficial for health because it has anti-inflammatory properties.\"\n",
    "\n",
    "# Dividir la consulta en palabras\n",
    "words = query.split()\n",
    "\n",
    "# Función para la predicción con LLM\n",
    "def predict_text(words_to_keep):\n",
    "    \"\"\"\n",
    "    Genera predicciones para la consulta manteniendo solo ciertas palabras activas.\n",
    "    \"\"\"\n",
    "    # Reconstruir el texto basado en las palabras seleccionadas\n",
    "    filtered_query = \" \".join([words[i] for i in range(len(words)) if words_to_keep[i] > 0.5])\n",
    "    \n",
    "    # Si no hay palabras, retorna un puntaje bajo por defecto\n",
    "    if not filtered_query.strip():\n",
    "        return [0.0]\n",
    "    \n",
    "    # Concatenar el texto filtrado con el texto objetivo\n",
    "    input_text = f\"{filtered_query} {target_text}\"\n",
    "    \n",
    "    # Realizar predicción con el modelo\n",
    "    prediction = llm(input_text)\n",
    "    \n",
    "    # Usar el puntaje de la clase positiva como salida\n",
    "    return [prediction[0][0]['score']]\n",
    "\n",
    "# Crear un conjunto de referencia inicial para SHAP\n",
    "reference = np.random.rand(100, len(words))  # Matriz bidimensional con valores aleatorios\n",
    "\n",
    "# Crear el explicador SHAP\n",
    "explainer = shap.KernelExplainer(predict_text, reference)\n",
    "\n",
    "# Calcular los valores SHAP para la consulta\n",
    "shap_values = explainer.shap_values(np.ones(len(words)))\n",
    "\n",
    "# Visualización de los valores SHAP\n",
    "shap.force_plot(\n",
    "    explainer.expected_value[0],\n",
    "    shap_values[0],\n",
    "    feature_names=words\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
